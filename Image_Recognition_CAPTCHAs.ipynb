{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMuOxgEKoJkv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string \n",
        "import tensorflow as tf\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk11hR05u_h1"
      },
      "outputs": [],
      "source": [
        "!mkdir images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTQdn9FHfUNj"
      },
      "outputs": [],
      "source": [
        "#parameters for generating captchas and pipeline \n",
        "letters     =string.ascii_letters\n",
        "digits      =string.digits       \n",
        "punctuation =string.punctuation\n",
        "list(punctuation).remove(\"/\")\n",
        "vocab =list(letters + digits + punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSrP0Rkog_gq",
        "outputId": "2f9cf93f-6755-4820-981e-f7e1f9de445a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
          ]
        }
      ],
      "source": [
        "print (vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly5CRMZgqSKu"
      },
      "source": [
        "# Generate CAPTCHA images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMXjgNyguRTN"
      },
      "source": [
        "## Install Python's captcha library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaEnkYMyuePK",
        "outputId": "3ea80932-f17a-4531-9ee7-19024af60c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captcha\n",
            "  Downloading captcha-0.4-py3-none-any.whl (102 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 30 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from captcha) (7.1.2)\n",
            "Installing collected packages: captcha\n",
            "Successfully installed captcha-0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install captcha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYvpR14Fuycn"
      },
      "outputs": [],
      "source": [
        "from captcha.image import ImageCaptcha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Y5h8uCvA-z"
      },
      "source": [
        "## CAPTCHA images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX__lZFszhNv"
      },
      "source": [
        " the function generates images  include 5 characters :\n",
        " - letters and numbers\n",
        " -  symbols and punctuations (optional) \n",
        "\n",
        "input:\n",
        "\n",
        "- ratio  \n",
        "\n",
        "    - letters : numbers : symbols\n",
        "- split percentage \n",
        "\n",
        "output:\n",
        "\n",
        "- Dictionary { keys -> train + validate + test , values -> list [ image path' , tag ] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ssns71Ku-X7"
      },
      "outputs": [],
      "source": [
        "def CAPTCHAsgenerating (datasize: int , imgsize : tuple , ratio :tuple ,tr_s :float ):\n",
        "  v_s = float((1-tr_s)/2)\n",
        "  data_dict = {'tr':[],'val':[],'ts':[]}\n",
        "  captcha =[]\n",
        "  image = ImageCaptcha(width = imgsize[0] , height = imgsize[1] )\n",
        "  for i in range(datasize):\n",
        "    letter = [random.choice(letters) for i in range(ratio[0]) ]\n",
        "    number = [random.choice(digits) for i in range(ratio[1]) ]\n",
        "    symbol = [random.choice(punctuation) for i in range(ratio[2]) if not '/']\n",
        "    captcha_text = [str(elem) for elem in letter+number+symbol ] \n",
        "    random.shuffle( captcha_text) \n",
        "    captcha_text = ''.join(captcha_text)\n",
        "    path = '/content/images/'+captcha_text+'.png'\n",
        "    captcha.append ([path,captcha_text])\n",
        "    data = image.generate(captcha_text) \n",
        "    image.write(captcha_text, path )\n",
        "    tr, val , ts = np.split(captcha, [int(len(captcha)*tr_s), int(len(captcha)*(1-v_s))])\n",
        "    data_dict['tr'].extend(tr)\n",
        "    data_dict['val'].extend(val)\n",
        "    data_dict['ts'].extend(ts)\n",
        "    \n",
        "  return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnNm50OQiF5F"
      },
      "outputs": [],
      "source": [
        "data_dict= CAPTCHAsgenerating(datasize= 50, imgsize =(280 , 90) , ratio = (3,2,1) ,tr_s =0.8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRaPyTrFB2kO",
        "outputId": "885a02ac-33f3-4035-87d2-de1ff2d40ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(['/content/images/G6M8i.png', 'G6M8i'], dtype='<U25'), array(['/content/images/bCp23.png', 'bCp23'], dtype='<U25'), array(['/content/images/09ehp.png', '09ehp'], dtype='<U25'), array(['/content/images/Jb07t.png', 'Jb07t'], dtype='<U25'), array(['/content/images/j0au0.png', 'j0au0'], dtype='<U25'), array(['/content/images/j0au0.png', 'j0au0'], dtype='<U25'), array(['/content/images/u3FD0.png', 'u3FD0'], dtype='<U25'), array(['/content/images/y3gz2.png', 'y3gz2'], dtype='<U25'), array(['/content/images/x1fJ1.png', 'x1fJ1'], dtype='<U25'), array(['/content/images/U98IE.png', 'U98IE'], dtype='<U25'), array(['/content/images/U98IE.png', 'U98IE'], dtype='<U25'), array(['/content/images/B40fZ.png', 'B40fZ'], dtype='<U25'), array(['/content/images/B40fZ.png', 'B40fZ'], dtype='<U25'), array(['/content/images/33Bhi.png', '33Bhi'], dtype='<U25'), array(['/content/images/33Bhi.png', '33Bhi'], dtype='<U25'), array(['/content/images/L15YT.png', 'L15YT'], dtype='<U25'), array(['/content/images/L15YT.png', 'L15YT'], dtype='<U25'), array(['/content/images/v6H4r.png', 'v6H4r'], dtype='<U25'), array(['/content/images/v6H4r.png', 'v6H4r'], dtype='<U25'), array(['/content/images/v9nG6.png', 'v9nG6'], dtype='<U25'), array(['/content/images/v6H4r.png', 'v6H4r'], dtype='<U25'), array(['/content/images/v9nG6.png', 'v9nG6'], dtype='<U25'), array(['/content/images/v9nG6.png', 'v9nG6'], dtype='<U25'), array(['/content/images/cUf28.png', 'cUf28'], dtype='<U25'), array(['/content/images/cUf28.png', 'cUf28'], dtype='<U25'), array(['/content/images/vh87i.png', 'vh87i'], dtype='<U25'), array(['/content/images/vh87i.png', 'vh87i'], dtype='<U25'), array(['/content/images/2WD0d.png', '2WD0d'], dtype='<U25'), array(['/content/images/2WD0d.png', '2WD0d'], dtype='<U25'), array(['/content/images/Gw1Z7.png', 'Gw1Z7'], dtype='<U25'), array(['/content/images/2WD0d.png', '2WD0d'], dtype='<U25'), array(['/content/images/Gw1Z7.png', 'Gw1Z7'], dtype='<U25'), array(['/content/images/1sPp7.png', '1sPp7'], dtype='<U25'), array(['/content/images/Gw1Z7.png', 'Gw1Z7'], dtype='<U25'), array(['/content/images/1sPp7.png', '1sPp7'], dtype='<U25'), array(['/content/images/21HQq.png', '21HQq'], dtype='<U25'), array(['/content/images/1sPp7.png', '1sPp7'], dtype='<U25'), array(['/content/images/21HQq.png', '21HQq'], dtype='<U25'), array(['/content/images/r7K2P.png', 'r7K2P'], dtype='<U25'), array(['/content/images/21HQq.png', '21HQq'], dtype='<U25'), array(['/content/images/r7K2P.png', 'r7K2P'], dtype='<U25'), array(['/content/images/hl7Z3.png', 'hl7Z3'], dtype='<U25'), array(['/content/images/r7K2P.png', 'r7K2P'], dtype='<U25'), array(['/content/images/hl7Z3.png', 'hl7Z3'], dtype='<U25'), array(['/content/images/Nal49.png', 'Nal49'], dtype='<U25'), array(['/content/images/r7K2P.png', 'r7K2P'], dtype='<U25'), array(['/content/images/hl7Z3.png', 'hl7Z3'], dtype='<U25'), array(['/content/images/Nal49.png', 'Nal49'], dtype='<U25'), array(['/content/images/hl7Z3.png', 'hl7Z3'], dtype='<U25'), array(['/content/images/Nal49.png', 'Nal49'], dtype='<U25'), array(['/content/images/UYS57.png', 'UYS57'], dtype='<U25'), array(['/content/images/Nal49.png', 'Nal49'], dtype='<U25'), array(['/content/images/UYS57.png', 'UYS57'], dtype='<U25'), array(['/content/images/d0KG2.png', 'd0KG2'], dtype='<U25'), array(['/content/images/UYS57.png', 'UYS57'], dtype='<U25'), array(['/content/images/d0KG2.png', 'd0KG2'], dtype='<U25'), array(['/content/images/DW78K.png', 'DW78K'], dtype='<U25'), array(['/content/images/d0KG2.png', 'd0KG2'], dtype='<U25'), array(['/content/images/DW78K.png', 'DW78K'], dtype='<U25'), array(['/content/images/Y4Ug1.png', 'Y4Ug1'], dtype='<U25'), array(['/content/images/d0KG2.png', 'd0KG2'], dtype='<U25'), array(['/content/images/DW78K.png', 'DW78K'], dtype='<U25'), array(['/content/images/Y4Ug1.png', 'Y4Ug1'], dtype='<U25'), array(['/content/images/PCm99.png', 'PCm99'], dtype='<U25'), array(['/content/images/DW78K.png', 'DW78K'], dtype='<U25'), array(['/content/images/Y4Ug1.png', 'Y4Ug1'], dtype='<U25'), array(['/content/images/PCm99.png', 'PCm99'], dtype='<U25'), array(['/content/images/2uZ8c.png', '2uZ8c'], dtype='<U25'), array(['/content/images/Y4Ug1.png', 'Y4Ug1'], dtype='<U25'), array(['/content/images/PCm99.png', 'PCm99'], dtype='<U25'), array(['/content/images/2uZ8c.png', '2uZ8c'], dtype='<U25'), array(['/content/images/a1wD9.png', 'a1wD9'], dtype='<U25'), array(['/content/images/PCm99.png', 'PCm99'], dtype='<U25'), array(['/content/images/2uZ8c.png', '2uZ8c'], dtype='<U25'), array(['/content/images/a1wD9.png', 'a1wD9'], dtype='<U25'), array(['/content/images/g8bP2.png', 'g8bP2'], dtype='<U25'), array(['/content/images/2uZ8c.png', '2uZ8c'], dtype='<U25'), array(['/content/images/a1wD9.png', 'a1wD9'], dtype='<U25'), array(['/content/images/g8bP2.png', 'g8bP2'], dtype='<U25'), array(['/content/images/HsG51.png', 'HsG51'], dtype='<U25'), array(['/content/images/2uZ8c.png', '2uZ8c'], dtype='<U25'), array(['/content/images/a1wD9.png', 'a1wD9'], dtype='<U25'), array(['/content/images/g8bP2.png', 'g8bP2'], dtype='<U25'), array(['/content/images/HsG51.png', 'HsG51'], dtype='<U25'), array(['/content/images/a1wD9.png', 'a1wD9'], dtype='<U25'), array(['/content/images/g8bP2.png', 'g8bP2'], dtype='<U25'), array(['/content/images/HsG51.png', 'HsG51'], dtype='<U25'), array(['/content/images/2zY4X.png', '2zY4X'], dtype='<U25'), array(['/content/images/g8bP2.png', 'g8bP2'], dtype='<U25'), array(['/content/images/HsG51.png', 'HsG51'], dtype='<U25'), array(['/content/images/2zY4X.png', '2zY4X'], dtype='<U25'), array(['/content/images/VIy63.png', 'VIy63'], dtype='<U25'), array(['/content/images/HsG51.png', 'HsG51'], dtype='<U25'), array(['/content/images/2zY4X.png', '2zY4X'], dtype='<U25'), array(['/content/images/VIy63.png', 'VIy63'], dtype='<U25'), array(['/content/images/s0s8w.png', 's0s8w'], dtype='<U25'), array(['/content/images/2zY4X.png', '2zY4X'], dtype='<U25'), array(['/content/images/VIy63.png', 'VIy63'], dtype='<U25'), array(['/content/images/s0s8w.png', 's0s8w'], dtype='<U25'), array(['/content/images/k5b9o.png', 'k5b9o'], dtype='<U25'), array(['/content/images/2zY4X.png', '2zY4X'], dtype='<U25'), array(['/content/images/VIy63.png', 'VIy63'], dtype='<U25'), array(['/content/images/s0s8w.png', 's0s8w'], dtype='<U25'), array(['/content/images/k5b9o.png', 'k5b9o'], dtype='<U25'), array(['/content/images/8Dzf2.png', '8Dzf2'], dtype='<U25'), array(['/content/images/VIy63.png', 'VIy63'], dtype='<U25'), array(['/content/images/s0s8w.png', 's0s8w'], dtype='<U25'), array(['/content/images/k5b9o.png', 'k5b9o'], dtype='<U25'), array(['/content/images/8Dzf2.png', '8Dzf2'], dtype='<U25'), array(['/content/images/Zl6U7.png', 'Zl6U7'], dtype='<U25'), array(['/content/images/s0s8w.png', 's0s8w'], dtype='<U25'), array(['/content/images/k5b9o.png', 'k5b9o'], dtype='<U25'), array(['/content/images/8Dzf2.png', '8Dzf2'], dtype='<U25'), array(['/content/images/Zl6U7.png', 'Zl6U7'], dtype='<U25'), array(['/content/images/4se6E.png', '4se6E'], dtype='<U25'), array(['/content/images/k5b9o.png', 'k5b9o'], dtype='<U25'), array(['/content/images/8Dzf2.png', '8Dzf2'], dtype='<U25'), array(['/content/images/Zl6U7.png', 'Zl6U7'], dtype='<U25'), array(['/content/images/4se6E.png', '4se6E'], dtype='<U25'), array(['/content/images/Llb58.png', 'Llb58'], dtype='<U25'), array(['/content/images/8Dzf2.png', '8Dzf2'], dtype='<U25'), array(['/content/images/Zl6U7.png', 'Zl6U7'], dtype='<U25'), array(['/content/images/4se6E.png', '4se6E'], dtype='<U25'), array(['/content/images/Llb58.png', 'Llb58'], dtype='<U25'), array(['/content/images/v56pt.png', 'v56pt'], dtype='<U25')]\n"
          ]
        }
      ],
      "source": [
        "print (data_dict['val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE8Q6tG0Kuk-"
      },
      "source": [
        "## Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEhHDAt-KyQe"
      },
      "outputs": [],
      "source": [
        "class pipeline(tf.keras.utils.Sequence):\n",
        "  def __init__(self,input_x,labels,vocab,resize_shape,batch_size,shuffle=True):\n",
        "    self.x = input_x  # pipeline input \n",
        "    self.y = labels   # pipeline output\n",
        "    self.resize_shape = resize_shape\n",
        "    # The pipeline needs to take ''' batch size ( 8 examples , 16 examples, 32 example, 48 example)\n",
        "    # and shuffle paremeter [ true - false ] to shuffle or not shuffle the data\n",
        "    self.vocab      = vocab\n",
        "    self.batch_size = batch_size  \n",
        "    self.shuffle    = shuffle \n",
        "\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    # This function determines the number of batches\n",
        "    return int(np.floor(len(self.y) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Get the current batch \n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    X, y = self.__get_batch(indexes)\n",
        "    return {'image':X,'label':y}\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.x))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __read_image(self,path):\n",
        "    ''' a function that reads the image and do resizing changes the color convention'''\n",
        "    img=cv2.imread(path)\n",
        "    dim = self.resize_shape[0:2]\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    img = img.astype('float32')\n",
        "\n",
        "    img = cv2.resize(img,dim)\n",
        "    #img = np.transpose(img, (1, 0, 2)) #img.transpose(1, 0, 2)\n",
        "    return img\n",
        "    \n",
        "  def __get_label(self,label_string):\n",
        "    ''' a function that converts string to the class number '''\n",
        "    # Creating a lookup layer with a known vocabulary\n",
        "    layer = tf.keras.layers.StringLookup(vocabulary=self.vocab)\n",
        "    return layer(tf.strings.unicode_split(label_string, input_encoding=\"UTF-8\"))\n",
        "\n",
        "  def __get_batch(self, list_IDs_temp):\n",
        "    '''\n",
        "    Does the following three main things:\n",
        "    1- Create two arrays for input and output with correct shapes\n",
        "    '''\n",
        "    X = np.empty((self.batch_size, self.resize_shape[0],self.resize_shape[1]),dtype=np.float32)\n",
        "    y = np.empty((self.batch_size, 5))\n",
        "\n",
        "    # Generate data\n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "      # Get expression\n",
        "      X[i,:,:] = self.__read_image(self.x[ID]).T\n",
        "\n",
        "      # store label\n",
        "      y[i,]    = self.__get_label(self.y[ID])\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm39ur-wKsXr"
      },
      "source": [
        "### Build pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iCnlY9sK1B1"
      },
      "outputs": [],
      "source": [
        "train_x= np.array( np.array( data_dict['tr' ] ) [:,0] )\n",
        "train_y= np.array( np.array( data_dict['tr' ] ) [:,1] )\n",
        "test_x = np.array( np.array( data_dict['ts' ] ) [:,0] )\n",
        "test_y = np.array( np.array( data_dict['ts' ] ) [:,1] )\n",
        "val_x  = np.array( np.array( data_dict['val'] ) [:,0] )\n",
        "val_y  = np.array( np.array( data_dict['val'] ) [:,1] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mpq2kYWmOj9J"
      },
      "outputs": [],
      "source": [
        "resize_shape= (180,45,1)\n",
        "batch_size = 32\n",
        "epochs     = 60\n",
        "\n",
        "train_generator = pipeline(input_x=train_x,labels = train_y,vocab=vocab\n",
        "                           ,resize_shape = resize_shape ,batch_size=batch_size)\n",
        "\n",
        "validation_generator = pipeline(input_x = val_x , labels = val_y,vocab=vocab\n",
        "                           ,resize_shape = resize_shape ,batch_size=batch_size)\n",
        "\n",
        "test_generator = pipeline(input_x = test_x , labels = test_y,vocab=vocab\n",
        "                           ,resize_shape = resize_shape ,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiODZyfbJN37"
      },
      "source": [
        "## Model Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loC1MKX9PG1t"
      },
      "source": [
        "Convoluional Base Block \n",
        "\n",
        "  - Input image shape: (200,50,1)\n",
        "  - 2 CNN layers with the following set of filters [ 32,64 ]\n",
        "  - Each cnn is followed by a maxpooling layer \n",
        "  - Flatten layer at the end \n",
        "  - 2 Bi-directional LSTM layers [128,64] \n",
        "  - Output Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZP1XVtTJXKn"
      },
      "outputs": [],
      "source": [
        "class Evaluation(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, val_data_gen, val_labels, test_data_gen, test_labels,multi=True):\n",
        "    super(tf.keras.callbacks.Callback, self).__init__()\n",
        "    self.test_data   = test_data_gen\n",
        "    self.val_labels  = val_labels\n",
        "    self.val_data    = val_data_gen\n",
        "    self.test_labels = test_labels\n",
        "\n",
        "    self.max_length  =  max([len(val_labels) for label in val_labels])\n",
        "\n",
        "    # Mapping integers back to original characters\n",
        "    self.num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary = vocab, mask_token=None, invert=True\n",
        "    )\n",
        "\n",
        "    if multi == True:\n",
        "      self.param = 'ovr'\n",
        "    else:\n",
        "      self.param = 'raise'\n",
        "\n",
        "  def decode_batch_predictions(self,pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :self.max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(self.num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "  \n",
        "  def text_recall(self,preds,labels):\n",
        "    compare = [int(i==j) for i,j in zip(preds,labels)]\n",
        "\n",
        "    return sum(compare)/len(compare)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    y_preds  = self.model.predict(self.val_data)\n",
        "    pred_text= self.decode_batch_predictions(y_preds)\n",
        "\n",
        "    print('\\n')\n",
        "    print(' | val_Recall : {:.02f} %'.format(self.text_recall(pred_text,self.val_labels)))\n",
        "\n",
        "    y_preds  = self.model.predict(self.test_data)\n",
        "    pred_text= self.decode_batch_predictions(y_preds)\n",
        "\n",
        "    print(' | test_Recall: {:.02f} %'.format(self.text_recall(pred_text,self.test_labels)))\n",
        "\n",
        "class CTCLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions\n",
        "        return y_pred\n",
        "\n",
        "def create_model(shape,n_fltr=32,n_nds_dns=16,n_nds_lstm=128):\n",
        "  # CNN layers \n",
        "  \n",
        "  ## Encoding part using a convolutional neural network base \n",
        "\n",
        "  image_width,image_height = shape[0],shape[1]\n",
        "\n",
        "  # 1 - Adding two input layers [ one for the input image, the other for input label ]\n",
        "  input_image = tf.keras.layers.Input(shape=(image_width,image_height,1),name='image',dtype=\"float32\")\n",
        "  input_label = tf.keras.layers.Input(name=\"label\",shape=(None,))\n",
        "\n",
        "  cnn_layer_1 = tf.keras.layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_image)\n",
        "\n",
        "  cnn_layer_1 = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(cnn_layer_1)\n",
        "\n",
        "  cnn_layer_2 = tf.keras.layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(cnn_layer_1)\n",
        "\n",
        "  cnn_layer_2 = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(cnn_layer_2)\n",
        "\n",
        "  # 2 - Flatten layer\n",
        "  new_shape = ((image_width // 4), (image_height // 4) * 64)\n",
        "  x = tf.keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(cnn_layer_2)\n",
        "  x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "  ## Decoding part \n",
        "  # LSTM [ upgraded RNN layer ]\n",
        "  bi_lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(n_nds_lstm, return_sequences=True))(x)\n",
        "  bi_lstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(n_nds_lstm//2, return_sequences=True))(bi_lstm1)\n",
        "\n",
        "  ## Output layer: the number of output nodes is equal to the number of characters in the vocab\n",
        "  out_layer = tf.keras.layers.Dense(len(vocab) + 1,activation=\"softmax\",name=\"output\")(bi_lstm2)\n",
        "\n",
        "  ## CTC layer to map back the model predictions to characters\n",
        "  decode_output = CTCLayer(name=\"Decodinglayer\")(input_label,out_layer)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_image, input_label], outputs=decode_output, name=\"Captcha_model\"\n",
        "  )\n",
        "\n",
        "  # Optimizer\n",
        "  opt = tf.keras.optimizers.Adam()\n",
        "  # Compile the model and return\n",
        "  model.compile(optimizer=opt)\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbi03La8rCST",
        "outputId": "f9e74dad-8e47-48be-ed71-3d89e59956ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        }
      ],
      "source": [
        "epochs = 500\n",
        "early_stopping_patience = 50\n",
        "# Add early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model = create_model(shape=resize_shape)\n",
        "\n",
        "evaluator = Evaluation(validation_generator, val_y , test_generator, test_y,multi=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping,evaluator],)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr2fPJsZo1Bz"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JAh0GkQpotdn"
      },
      "outputs": [],
      "source": [
        "# Get the prediction model by extracting layers till the output layer\n",
        "model = tf.keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"output\").output\n",
        ")\n",
        "\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary = vocab, mask_token=None, invert=True)\n",
        "\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred,vocab,max_length):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary = vocab, mask_token=None, invert=True\n",
        "    )\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "#  Let's check results on some validation samples\n",
        "\n",
        "\n",
        "preds = model.predict(test_generator)\n",
        "pred_texts = decode_batch_predictions(preds,vocab=vocab,max_length=5)\n",
        "\n",
        "def text_recall(preds,labels):\n",
        "  compare = [int(i==j) for i,j in zip(preds,labels)]\n",
        "\n",
        "  return sum(compare)/len(compare)\n",
        "\n",
        "\n",
        "print(\"Test Recall: \",sum([int(i==j) for i,j in zip(pred_texts,test_y)])/len(test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qsImtKlX-dJg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}